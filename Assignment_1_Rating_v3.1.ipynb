{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 258 Assignment 1 Rating\n",
    "**Ming Ki Toby Cheng**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "from sklearn import linear_model\n",
    "import numpy\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, \"rt\"):\n",
    "        yield eval(l)\n",
    "\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, \"rt\")\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining MSE function\n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, item):\n",
    "    if user not in userBiases and item in itemBiases:\n",
    "        return alpha + itemBiases[item]\n",
    "    if user in userBiases and item not in itemBiases:\n",
    "        return alpha + userBiases[user]\n",
    "    if user not in userBiases and item not in itemBiases:\n",
    "        return alpha\n",
    "    if user in userBiases and item in itemBiases:\n",
    "        return alpha + userBiases[user] + itemBiases[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "books = []\n",
    "ratings = []\n",
    "\n",
    "for user, book, _ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    users.append(user)\n",
    "    books.append(book)\n",
    "    ratings.append(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = list(zip(users, books, ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rating = []\n",
    "userRatings = defaultdict(list)\n",
    "bookRatings = defaultdict(list)\n",
    "\n",
    "\n",
    "for user, book, r in all_data:\n",
    "    all_rating.append(int(r))\n",
    "    userRatings[user].append(int(r))\n",
    "    bookRatings[book].append(int(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAverage = sum(all_rating) / len(all_rating)\n",
    "\n",
    "alpha = allAverage\n",
    "nUsers = len(userRatings)\n",
    "nItems = len(bookRatings)\n",
    "users = list(userRatings.keys())\n",
    "items = list(bookRatings.keys())\n",
    "\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d[0], d[1]) for d in all_data]\n",
    "    cost = MSE(predictions, labels)\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(all_data)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for d in all_data:\n",
    "        u,i = d[0], d[1]\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - int(d[2])\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    return numpy.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [int(d[2]) for d in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 1.4744154699735492\n",
      "MSE = 1.4570319169995913\n",
      "MSE = 1.393533889858659\n",
      "MSE = 7.895479454540844\n",
      "MSE = 1.370350294778541\n",
      "MSE = 1.2066366132890634\n",
      "MSE = 1.2051200097212715\n",
      "MSE = 1.1991489285514936\n",
      "MSE = 1.176789933496203\n",
      "MSE = 1.063003446196276\n",
      "MSE = 1.0135355949628004\n",
      "MSE = 0.9839360442345014\n",
      "MSE = 0.9692487850331981\n",
      "MSE = 0.958484006943688\n",
      "MSE = 0.9436564302519366\n",
      "MSE = 0.9353114927636458\n",
      "MSE = 0.9331309898907322\n",
      "MSE = 0.932368037231562\n",
      "MSE = 0.9306453149999646\n",
      "MSE = 0.9290699136177415\n",
      "MSE = 0.9283440069087131\n",
      "MSE = 0.9278096284027274\n",
      "MSE = 0.9274843737623956\n",
      "MSE = 0.9270731872454248\n",
      "MSE = 0.9266477258480118\n",
      "MSE = 0.9265189166652921\n",
      "MSE = 0.9265431912685078\n",
      "MSE = 0.9266365358524254\n",
      "MSE = 0.926699721339586\n",
      "MSE = 0.9265715822785244\n",
      "MSE = 0.9274028964494504\n",
      "MSE = 0.9266224848116169\n",
      "MSE = 0.9263279285056032\n",
      "MSE = 0.9260054672023919\n",
      "MSE = 0.9261801641225601\n",
      "MSE = 0.9259955473589025\n",
      "MSE = 0.9264065294843348\n",
      "MSE = 0.9260222882906745\n",
      "MSE = 0.9260071499269964\n",
      "MSE = 0.9260520695654878\n",
      "MSE = 0.9260873434200171\n",
      "MSE = 0.9261257501063017\n",
      "MSE = 0.9260646242658673\n",
      "MSE = 0.9260321973976158\n",
      "MSE = 0.9325227776126647\n",
      "MSE = 0.926052121090764\n",
      "MSE = 0.9260208158540522\n",
      "MSE = 0.9260076219886519\n",
      "MSE = 0.9259482522558201\n",
      "MSE = 0.9289944573568184\n",
      "MSE = 0.9260137216255807\n",
      "MSE = 0.925997342713878\n",
      "MSE = 0.9260078923158035\n",
      "MSE = 0.9260226946593696\n",
      "MSE = 0.9260285080311583\n",
      "MSE = 0.9260166161583775\n",
      "MSE = 0.9259538780474093\n",
      "MSE = 0.9306314140383712\n",
      "MSE = 0.9259622017951308\n",
      "MSE = 0.9258775070719437\n",
      "MSE = 0.9258229458018714\n",
      "MSE = 0.925793339914337\n",
      "MSE = 0.9257834579150686\n",
      "MSE = 0.9256884487078288\n",
      "MSE = 0.9258073688790924\n",
      "MSE = 0.9257383285220441\n",
      "MSE = 0.9257200883552621\n",
      "MSE = 0.9256971613421332\n",
      "MSE = 0.9256907877169532\n",
      "MSE = 0.925678759497432\n",
      "MSE = 0.9255154015292192\n",
      "MSE = 0.9256705699231456\n",
      "MSE = 0.9256618164643625\n",
      "MSE = 0.925792419427117\n",
      "MSE = 0.9256821212701771\n",
      "MSE = 0.9256714373243486\n",
      "MSE = 0.9255734353747642\n",
      "MSE = 0.9258971721138718\n",
      "MSE = 0.9256096688323036\n",
      "MSE = 0.9255252580103338\n",
      "MSE = 0.9255213441436358\n",
      "MSE = 0.9255023126782697\n",
      "MSE = 0.9255160247165505\n",
      "MSE = 0.9255168212129983\n",
      "MSE = 0.9255156780385623\n",
      "MSE = 0.9255158351876548\n",
      "MSE = 0.9253578218668729\n",
      "MSE = 0.9254853598956333\n",
      "MSE = 0.9254733267506722\n",
      "MSE = 0.9254475980084566\n",
      "MSE = 0.9254431485024638\n",
      "MSE = 0.9253456803640212\n",
      "MSE = 0.9254798766865421\n",
      "MSE = 0.9253820479623719\n",
      "MSE = 0.9253938058286386\n",
      "MSE = 0.9253980328304017\n",
      "MSE = 0.9254004035995442\n",
      "MSE = 0.9253951889965012\n",
      "MSE = 0.9253824666301996\n",
      "MSE = 0.9253444230452033\n",
      "MSE = 0.9253506982430673\n",
      "MSE = 0.9253505778180643\n",
      "MSE = 0.9253436794381167\n",
      "MSE = 0.9253466791587726\n",
      "MSE = 0.9253414359586932\n",
      "MSE = 0.9253569447958272\n",
      "MSE = 0.9253334768305809\n",
      "MSE = 0.9253394728618659\n",
      "MSE = 0.9253414396125279\n",
      "MSE = 0.9253427060293881\n",
      "MSE = 0.9253451310659414\n",
      "MSE = 0.9253513774275751\n",
      "MSE = 0.927358577651685\n",
      "MSE = 0.9253471848454276\n",
      "MSE = 0.9253506011199737\n",
      "MSE = 0.9253502934742844\n",
      "MSE = 0.9253487161049126\n",
      "MSE = 0.9253488674674066\n",
      "MSE = 0.9253504668577103\n",
      "MSE = 0.9253628301495902\n",
      "MSE = 0.9253742827745325\n",
      "MSE = 0.9253813240101073\n",
      "MSE = 0.9253824984479947\n",
      "MSE = 0.9254261284086923\n",
      "MSE = 0.9253858259505116\n",
      "MSE = 0.925793704526327\n",
      "MSE = 0.9253881517810568\n",
      "MSE = 0.9253883155192871\n",
      "MSE = 0.9253871563771972\n",
      "MSE = 0.925385574605421\n",
      "MSE = 0.9253827297030337\n",
      "MSE = 0.9253819928217806\n",
      "MSE = 0.9253824572278695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 3.81227183, -0.02013682,  0.257077  , ..., -0.28247759,\n",
       "        -0.48340748, -0.24948904]),\n",
       " 0.997802847685844,\n",
       " {'grad': array([-7.40579398e-06, -1.31068698e-07,  1.96913843e-07, ...,\n",
       "          4.54754267e-07,  5.88199412e-08,  8.77511889e-07]),\n",
       "  'task': b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL',\n",
       "  'funcalls': 133,\n",
       "  'nit': 114,\n",
       "  'warnflag': 0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(nUsers+nItems),\n",
    "                             derivative, args = (labels, 0.0000168))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing predictions of test set to file\n",
    "predictions = open(\"predictions_Rating_Assignment1_v3.1.txt\", \"w\")\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        # header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u, b = l.strip().split(\"-\")\n",
    "    \n",
    "    predictions.write(u + \"-\" + b + \",\" + str(prediction(u,b)) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using previous lambda now use all the data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratngs = list(zip(users, books, ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7469372221d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbooksPerUser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_ratings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0musersPerBook\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbooksPerUser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_ratings' is not defined"
     ]
    }
   ],
   "source": [
    "# Forming dictionary with user and book combinations\n",
    "ratingPerCombo = {}\n",
    "usersPerBook = defaultdict(set)\n",
    "booksPerUser = defaultdict(set)\n",
    "\n",
    "for user, book,r in all_ratings:\n",
    "    usersPerBook[book].add(user)\n",
    "    booksPerUser[user].add(book)\n",
    "    ratingPerCombo[(user,book)] = int(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing all user ratings and all books dictionaries\n",
    "totalRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "bookRatings = defaultdict(list)\n",
    "\n",
    "# All ratings for each user and each book\n",
    "for user, book, r in all_ratings:\n",
    "    r = int(r)\n",
    "    totalRatings.append(r)\n",
    "    userRatings[user].append(r)\n",
    "    bookRatings[book].append(r)\n",
    "\n",
    "globalAverage = sum(totalRatings) / len(totalRatings)\n",
    "userAverage = {}\n",
    "userBias = {}\n",
    "user_total = 0\n",
    "bookAverage = {}\n",
    "bookBias = {}\n",
    "book_total = 0\n",
    "\n",
    "# Initializing user and book biases\n",
    "for user in userRatings:\n",
    "    userAverage[user] = sum(userRatings[user]) / len(userRatings[user])\n",
    "    \n",
    "for user in userAverage:\n",
    "    user_total += float(userAverage[user])\n",
    "    \n",
    "for user in userAverage:\n",
    "    userBias[user] = userAverage[user] - (user_total/len(userAverage))\n",
    "\n",
    "for book in bookRatings:\n",
    "    bookAverage[book] = sum(bookRatings[book]) / len(bookRatings[book])\n",
    "    \n",
    "for book in bookAverage:\n",
    "    book_total += float(bookAverage[book])\n",
    "    \n",
    "for book in bookAverage:\n",
    "    bookBias[book] = bookAverage[book] - (book_total/len(bookAverage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining alpha, bookBias, userBias by convergence from Training data and lambda value 1\n",
    "lamb = 3.15\n",
    "alpha_sum = 0\n",
    "alpha = 0\n",
    "MSE_diff = 5\n",
    "trial = 0\n",
    "\n",
    "while MSE_diff > 0.00005 or trial > 1000:\n",
    "    model_predictions = []\n",
    "    actual_rating = []\n",
    "    alpha_sum = 0\n",
    "    \n",
    "    for user, book, r in all_ratings:\n",
    "        alpha_sum += (r-(userBias[user] + bookBias[book]))\n",
    "    alpha = alpha_sum/len(all_ratings)\n",
    "    \n",
    "    for user in booksPerUser:\n",
    "        beta_U_Sum = 0\n",
    "        for books in booksPerUser[user]:\n",
    "            beta_U_Sum += ratingPerCombo[user,books] - (alpha + bookBias[books])\n",
    "        userBias[user] = beta_U_Sum/(lamb+ len(booksPerUser[user]))\n",
    "    \n",
    "    for book in usersPerBook:\n",
    "        beta_I_Sum = 0\n",
    "        for users in usersPerBook[book]:\n",
    "            beta_I_Sum += ratingPerCombo[users,book] - (alpha + userBias[users])\n",
    "        bookBias[book] = beta_I_Sum/(lamb+ len(usersPerBook[book]))\n",
    "    \n",
    "    for user, book, r in all_ratings:\n",
    "        model_predictions.append(int(prediction(user, book)))\n",
    "        actual_rating.append(r)\n",
    "    \n",
    "    if trial == 0:\n",
    "        MSE_0 = 0\n",
    "\n",
    "    MSE_1 = MSE(model_predictions, actual_rating)\n",
    "    \n",
    "    MSE_diff = abs(MSE_1 - MSE_0)\n",
    "\n",
    "    print('MSE_new:', MSE_1)\n",
    "    \n",
    "    MSE_0 = MSE_1\n",
    "    trial += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions and MSE on validation data\n",
    "model_predictions = []\n",
    "for user, book, r in validation_rating:\n",
    "    model_predictions.append(prediction(user, book))\n",
    "\n",
    "MSE_valid = MSE(model_predictions, ratings_valid)\n",
    "print('MSE on validation set:',MSE_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing predictions of test set to file\n",
    "predictions = open(\"predictions_Rating_Assignment1.txt\", \"w\")\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        # header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u, b = l.strip().split(\"-\")\n",
    "    \n",
    "    predictions.write(u + \"-\" + b + \",\" + str(prediction(u,b)) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle Username: tobycheng or Toby Cheng**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle Rating MSE: 1.13707**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
