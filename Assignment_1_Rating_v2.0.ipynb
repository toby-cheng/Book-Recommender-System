{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 258 Assignment 1 Rating\n",
    "**Ming Ki Toby Cheng**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "from sklearn import linear_model\n",
    "import numpy\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, \"rt\"):\n",
    "        yield eval(l)\n",
    "\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, \"rt\")\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining MSE function\n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "books = []\n",
    "ratings = []\n",
    "\n",
    "for user, book, _ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    users.append(user)\n",
    "    books.append(book)\n",
    "    ratings.append(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initializing data\n",
    "users_train = users[:190000]\n",
    "books_train = books[:190000]\n",
    "ratings_train = ratings[:190000]\n",
    "users_valid = users[190000:]\n",
    "books_valid = books[190000:]\n",
    "ratings_valid = ratings[190000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rating = list(zip(users_train, books_train, ratings_train))\n",
    "validation_rating = list(zip(users_valid, books_valid, ratings_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rating = []\n",
    "userRatings = defaultdict(list)\n",
    "bookRatings = defaultdict(list)\n",
    "\n",
    "\n",
    "for user, book, r in training_rating:\n",
    "    train_rating.append(int(r))\n",
    "    userRatings[user].append(int(r))\n",
    "    bookRatings[book].append(int(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAverage = sum(train_rating) / len(train_rating)\n",
    "\n",
    "alpha = trainAverage\n",
    "nUsers = len(userRatings)\n",
    "nItems = len(bookRatings)\n",
    "users = list(userRatings.keys())\n",
    "items = list(bookRatings.keys())\n",
    "\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "userGamma = defaultdict(float)\n",
    "itemGamma = defaultdict(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1\n",
    "for u in userRatings:\n",
    "    userGamma[u] = [random.random() * 0.1 - 0.05 for k in range(K)]\n",
    "for i in bookRatings:\n",
    "    itemGamma[i] = [random.random() * 0.1 - 0.05 for k in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    global userGamma\n",
    "    global itemGamma\n",
    "    index = 0\n",
    "    alpha = theta[index]\n",
    "    index += 1\n",
    "    userBiases = dict(zip(users, theta[index:index+nUsers]))\n",
    "    index += nUsers\n",
    "    itemBiases = dict(zip(items, theta[index:index+nItems]))\n",
    "    index += nItems\n",
    "    for u in users:\n",
    "        userGamma[u] = theta[index:index+K]\n",
    "        index += K\n",
    "    for i in items:\n",
    "        itemGamma[i] = theta[index:index+K]\n",
    "        index += K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner(x, y):\n",
    "    return sum([a*b for a,b in zip(x,y)])\n",
    "\n",
    "# def prediction(user, item):\n",
    "#      return alpha + userBiases[user] + itemBiases[item] + inner(userGamma[user], itemGamma[item])\n",
    "\n",
    "# Defining predictor function\n",
    "def prediction(user, item):\n",
    "    if user not in userBiases and item in itemBiases:\n",
    "        return alpha + itemBiases[item]\n",
    "    if user in userBiases and item not in itemBiases:\n",
    "        return alpha + userBiases[user]\n",
    "    if user not in userBiases and item not in itemBiases:\n",
    "        return alpha\n",
    "    if user in userBiases and item in itemBiases:\n",
    "        return alpha + userBiases[user] + itemBiases[item] + inner(userGamma[user], itemGamma[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d[0], d[1]) for d in training_rating]\n",
    "    cost = MSE(predictions, labels)\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    for u in users:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "        for k in range(K):\n",
    "            cost += lamb*userGamma[u][k]**2\n",
    "    for i in items:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "        for k in range(K):\n",
    "            cost += lamb*itemGamma[i][k]**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(training_rating)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    dUserGamma = {}\n",
    "    dItemGamma = {}\n",
    "    for u in userRatings:\n",
    "        dUserGamma[u] = [0.0 for k in range(K)]\n",
    "    for i in bookRatings:\n",
    "        dItemGamma[i] = [0.0 for k in range(K)]\n",
    "    for d in training_rating:\n",
    "        u,i = d[0], d[1]\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - int(d[2])\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "        for k in range(K):\n",
    "            dUserGamma[u][k] += 2/N*itemGamma[i][k]*diff\n",
    "            dItemGamma[i][k] += 2/N*userGamma[u][k]*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "        for k in range(K):\n",
    "            dUserGamma[u][k] += 2*lamb*userGamma[u][k]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "        for k in range(K):\n",
    "            dItemGamma[i][k] += 2*lamb*itemGamma[i][k]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    for u in users:\n",
    "        dtheta += dUserGamma[u]\n",
    "    for i in items:\n",
    "        dtheta += dItemGamma[i]\n",
    "    return numpy.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [int(d[2]) for d in training_rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 1.4735497584932453\n",
      "MSE = 1.4561022672576671\n",
      "MSE = 1.392315273385649\n",
      "MSE = 8.073102620738412\n",
      "MSE = 1.3750058885332772\n",
      "MSE = 1.2119086141150166\n",
      "MSE = 1.2103906463933831\n",
      "MSE = 1.2044224527934595\n",
      "MSE = 1.1822085137951317\n",
      "MSE = 1.07588008150663\n",
      "MSE = 1.0457248331346796\n",
      "MSE = 1.0191965181595632\n",
      "MSE = 1.0150351632159835\n",
      "MSE = 1.0165950844639755\n",
      "MSE = 1.0164807340050686\n",
      "MSE = 1.0154383720483349\n",
      "MSE = 1.0141403208116053\n",
      "MSE = 1.0139030271925975\n",
      "MSE = 1.013997140381256\n",
      "MSE = 1.019516169145231\n",
      "MSE = 1.0139937532459375\n",
      "MSE = 1.0138315591497997\n",
      "MSE = 1.0137498537704501\n",
      "MSE = 1.0136440751741382\n",
      "MSE = 1.0136546270664304\n",
      "MSE = 1.0137898348256824\n",
      "MSE = 1.0139059612337105\n",
      "MSE = 1.01391201526589\n",
      "MSE = 1.013912649690732\n",
      "MSE = 1.0137326725621756\n",
      "MSE = 1.0084504125083744\n",
      "MSE = 1.0131576783447587\n",
      "MSE = 1.012084938925759\n",
      "MSE = 1.0114747642721849\n",
      "MSE = 1.0114740875218557\n",
      "MSE = 1.0094119327732838\n",
      "MSE = 1.0104216723689758\n",
      "MSE = 1.0100236959101812\n",
      "MSE = 1.0099198610512967\n",
      "MSE = 1.0097993025494842\n",
      "MSE = 1.0092545080438158\n",
      "MSE = 1.0095159588962395\n",
      "MSE = 1.0094098785003378\n",
      "MSE = 1.0089987722357985\n",
      "MSE = 1.0088703224928037\n",
      "MSE = 1.0087861221707155\n",
      "MSE = 1.0086976264346785\n",
      "MSE = 1.0086056245179724\n",
      "MSE = 1.0081489799373675\n",
      "MSE = 1.0083965551512606\n",
      "MSE = 1.0084659641509095\n",
      "MSE = 1.008472438027448\n",
      "MSE = 1.0083390924341828\n",
      "MSE = 1.008064056540559\n",
      "MSE = 1.0074489794040549\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-88ba1100bc7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                    \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnUsers\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnItems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;31m# Initialize beta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.05\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnUsers\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnItems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Gamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                              derivative, args = (labels, 0.00007))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-074494d45be2>\u001b[0m in \u001b[0;36mcost\u001b[0;34m(theta, labels, lamb)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_rating\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MSE = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-074494d45be2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_rating\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MSE = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4539cb4a283f>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(user, item)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muserBiases\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitemBiases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muserBiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitemBiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserGamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemGamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-4539cb4a283f>\u001b[0m in \u001b[0;36minner\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# def prediction(user, item):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#      return alpha + userBiases[user] + itemBiases[item] + inner(userGamma[user], itemGamma[item])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4539cb4a283f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# def prediction(user, item):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#      return alpha + userBiases[user] + itemBiases[item] + inner(userGamma[user], itemGamma[item])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + # Initialize alpha\n",
    "                                   [0.0]*(nUsers+nItems) + # Initialize beta\n",
    "                                   [random.random() * 0.1 - 0.05 for k in range(K*(nUsers+nItems))], # Gamma\n",
    "                             derivative, args = (labels, 0.00007))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = []\n",
    "real_rate = []\n",
    "for user, book, rating in validation_rating:\n",
    "    val_pred.append(prediction(user,book))\n",
    "    real_rate.append(int(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE(val_pred,real_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda: 0.0005, 0.0001 \n",
    "MSE: 1.340872431, 1.177193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing user and book biases\n",
    "\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "userBias = {}\n",
    "user_total = 0\n",
    "bookAverage = {}\n",
    "bookBias = {}\n",
    "book_total = 0\n",
    "\n",
    "\n",
    "for user in userRatings:\n",
    "    userAverage[user] = sum(userRatings[user]) / len(userRatings[user])\n",
    "    \n",
    "for user in userAverage:\n",
    "    user_total += float(userAverage[user])\n",
    "    \n",
    "for user in userAverage:\n",
    "    userBias[user] = userAverage[user] - (user_total/len(userAverage))\n",
    "\n",
    "for book in bookRatings:\n",
    "    bookAverage[book] = sum(bookRatings[book]) / len(bookRatings[book])\n",
    "    \n",
    "for book in bookAverage:\n",
    "    book_total += float(bookAverage[book])\n",
    "    \n",
    "for book in bookAverage:\n",
    "    bookBias[book] = bookAverage[book] - (book_total/len(bookAverage))\n",
    "\n",
    "# Defining alpha, bookBias, userBias by convergence from Training data and new lambda value\n",
    "Reg = []\n",
    "MSE_val = []\n",
    "\n",
    "for i in numpy.arange(2.75, 3.5, 0.01):\n",
    "    lamb = i\n",
    "    alpha_sum = 0\n",
    "    alpha = globalAverage\n",
    "    MSE_diff = 5\n",
    "    trial = 0\n",
    "\n",
    "    while MSE_diff > 0.00005 or trial > 1000:\n",
    "        model_predictions = []\n",
    "        alpha_sum = 0\n",
    "        for user, book, r in training_rating:\n",
    "            alpha_sum += (int(r)-(userBias[user] + bookBias[book]))\n",
    "        alpha = alpha_sum/len(training_rating)\n",
    "\n",
    "        for user in booksPerUser:\n",
    "            beta_U_Sum = 0\n",
    "            for books in booksPerUser[user]:\n",
    "                beta_U_Sum += ratingPerCombo[user,books] - (alpha + bookBias[books])\n",
    "            userBias[user] = beta_U_Sum/(lamb+ len(booksPerUser[user]))\n",
    "\n",
    "        for book in usersPerBook:\n",
    "            beta_I_Sum = 0\n",
    "            for users in usersPerBook[book]:\n",
    "                beta_I_Sum += ratingPerCombo[users,book] - (alpha + userBias[users])\n",
    "            bookBias[book] = beta_I_Sum/(lamb+ len(usersPerBook[book]))\n",
    "\n",
    "        for user, book, r in training_rating:\n",
    "            model_predictions.append(prediction(user, book))\n",
    "\n",
    "        #print('Trial #:',trial)\n",
    "\n",
    "        if trial == 0:\n",
    "            MSE_0 = 0\n",
    "\n",
    "        MSE_1 = MSE(model_predictions, ratings_train)\n",
    "\n",
    "        MSE_diff = abs(MSE_1 - MSE_0)\n",
    "\n",
    "        #if trial != 0:\n",
    "            #print('MSE_diff:', MSE_diff)\n",
    "\n",
    "        #print('MSE_old', MSE_0)\n",
    "        #print('MSE_new:', MSE_1)\n",
    "\n",
    "        MSE_0 = MSE_1\n",
    "        trial += 1 \n",
    "        # Predictions and MSE on validation data\n",
    "        \n",
    "    model_predictions = []\n",
    "    for user, book, r in validation_rating:\n",
    "        model_predictions.append(prediction(user, book))\n",
    "\n",
    "    MSE_valid = MSE(model_predictions, ratings_valid)\n",
    "    Reg.append(i)\n",
    "    MSE_val.append(MSE_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions and MSE on validation data\n",
    "model_predictions = []\n",
    "for user, book, r in validation_rating:\n",
    "    model_predictions.append(prediction(user, book))\n",
    "\n",
    "MSE_valid = MSE(model_predictions, ratings_valid)\n",
    "print(MSE_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Reg, MSE_val, 'r--')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Regularization Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE_val.index(min(MSE_val)),Reg[MSE_val.index(min(MSE_val))], min(MSE_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining alpha, bookBias, userBias by convergence from Training data and lambda value 1\n",
    "lamb = 3.15\n",
    "alpha_sum = 0\n",
    "alpha = 0\n",
    "MSE_diff = 5\n",
    "trial = 0\n",
    "\n",
    "while MSE_diff > 0.00005 or trial > 1000:\n",
    "    model_predictions = []\n",
    "    alpha_sum = 0\n",
    "    \n",
    "    for user, book, r in training_rating:\n",
    "        alpha_sum += (r-(userBias[user] + bookBias[book]))\n",
    "    alpha = alpha_sum/len(training_rating)\n",
    "    \n",
    "    for user in booksPerUser:\n",
    "        beta_U_Sum = 0\n",
    "        for books in booksPerUser[user]:\n",
    "            beta_U_Sum += ratingPerCombo[user,books] - (alpha + bookBias[books])\n",
    "        userBias[user] = beta_U_Sum/(lamb+ len(booksPerUser[user]))\n",
    "    \n",
    "    for book in usersPerBook:\n",
    "        beta_I_Sum = 0\n",
    "        for users in usersPerBook[book]:\n",
    "            beta_I_Sum += ratingPerCombo[users,book] - (alpha + userBias[users])\n",
    "        bookBias[book] = beta_I_Sum/(lamb+ len(usersPerBook[book]))\n",
    "    \n",
    "    for user, book, r in training_rating:\n",
    "        model_predictions.append(prediction(user, book))\n",
    "    \n",
    "    if trial == 0:\n",
    "        MSE_0 = 0\n",
    "\n",
    "    MSE_1 = MSE(model_predictions, ratings_train)\n",
    "    \n",
    "    MSE_diff = abs(MSE_1 - MSE_0)\n",
    "\n",
    "    print('MSE_new:', MSE_1)\n",
    "    \n",
    "    MSE_0 = MSE_1\n",
    "    trial += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions and MSE on validation data\n",
    "model_predictions = []\n",
    "for user, book, r in validation_rating:\n",
    "    model_predictions.append(prediction(user, book))\n",
    "\n",
    "MSE_valid = MSE(model_predictions, ratings_valid)\n",
    "print(MSE_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using previous lambda now use all the data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "books = []\n",
    "ratings = []\n",
    "for user, book, _ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    users.append(user)\n",
    "    books.append(book)\n",
    "    ratings.append(int(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings = list(zip(users, books, ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forming dictionary with user and book combinations\n",
    "ratingPerCombo = {}\n",
    "usersPerBook = defaultdict(set)\n",
    "booksPerUser = defaultdict(set)\n",
    "\n",
    "for user, book,r in all_ratings:\n",
    "    usersPerBook[book].add(user)\n",
    "    booksPerUser[user].add(book)\n",
    "    ratingPerCombo[(user,book)] = int(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing all user ratings and all books dictionaries\n",
    "totalRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "bookRatings = defaultdict(list)\n",
    "\n",
    "# All ratings for each user and each book\n",
    "for user, book, r in all_ratings:\n",
    "    r = int(r)\n",
    "    totalRatings.append(r)\n",
    "    userRatings[user].append(r)\n",
    "    bookRatings[book].append(r)\n",
    "\n",
    "globalAverage = sum(totalRatings) / len(totalRatings)\n",
    "userAverage = {}\n",
    "userBias = {}\n",
    "user_total = 0\n",
    "bookAverage = {}\n",
    "bookBias = {}\n",
    "book_total = 0\n",
    "\n",
    "# Initializing user and book biases\n",
    "for user in userRatings:\n",
    "    userAverage[user] = sum(userRatings[user]) / len(userRatings[user])\n",
    "    \n",
    "for user in userAverage:\n",
    "    user_total += float(userAverage[user])\n",
    "    \n",
    "for user in userAverage:\n",
    "    userBias[user] = userAverage[user] - (user_total/len(userAverage))\n",
    "\n",
    "for book in bookRatings:\n",
    "    bookAverage[book] = sum(bookRatings[book]) / len(bookRatings[book])\n",
    "    \n",
    "for book in bookAverage:\n",
    "    book_total += float(bookAverage[book])\n",
    "    \n",
    "for book in bookAverage:\n",
    "    bookBias[book] = bookAverage[book] - (book_total/len(bookAverage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining alpha, bookBias, userBias by convergence from Training data and lambda value 1\n",
    "lamb = 3.15\n",
    "alpha_sum = 0\n",
    "alpha = 0\n",
    "MSE_diff = 5\n",
    "trial = 0\n",
    "\n",
    "while MSE_diff > 0.00005 or trial > 1000:\n",
    "    model_predictions = []\n",
    "    actual_rating = []\n",
    "    alpha_sum = 0\n",
    "    \n",
    "    for user, book, r in all_ratings:\n",
    "        alpha_sum += (r-(userBias[user] + bookBias[book]))\n",
    "    alpha = alpha_sum/len(all_ratings)\n",
    "    \n",
    "    for user in booksPerUser:\n",
    "        beta_U_Sum = 0\n",
    "        for books in booksPerUser[user]:\n",
    "            beta_U_Sum += ratingPerCombo[user,books] - (alpha + bookBias[books])\n",
    "        userBias[user] = beta_U_Sum/(lamb+ len(booksPerUser[user]))\n",
    "    \n",
    "    for book in usersPerBook:\n",
    "        beta_I_Sum = 0\n",
    "        for users in usersPerBook[book]:\n",
    "            beta_I_Sum += ratingPerCombo[users,book] - (alpha + userBias[users])\n",
    "        bookBias[book] = beta_I_Sum/(lamb+ len(usersPerBook[book]))\n",
    "    \n",
    "    for user, book, r in all_ratings:\n",
    "        model_predictions.append(int(prediction(user, book)))\n",
    "        actual_rating.append(r)\n",
    "    \n",
    "    if trial == 0:\n",
    "        MSE_0 = 0\n",
    "\n",
    "    MSE_1 = MSE(model_predictions, actual_rating)\n",
    "    \n",
    "    MSE_diff = abs(MSE_1 - MSE_0)\n",
    "\n",
    "    print('MSE_new:', MSE_1)\n",
    "    \n",
    "    MSE_0 = MSE_1\n",
    "    trial += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions and MSE on validation data\n",
    "model_predictions = []\n",
    "for user, book, r in validation_rating:\n",
    "    model_predictions.append(prediction(user, book))\n",
    "\n",
    "MSE_valid = MSE(model_predictions, ratings_valid)\n",
    "print('MSE on validation set:',MSE_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing predictions of test set to file\n",
    "predictions = open(\"predictions_Rating_Assignment1.txt\", \"w\")\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        # header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u, b = l.strip().split(\"-\")\n",
    "    \n",
    "    predictions.write(u + \"-\" + b + \",\" + str(prediction(u,b)) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle Username: tobycheng or Toby Cheng**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle Rating MSE: 1.13707**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
